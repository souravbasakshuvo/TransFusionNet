{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "61777543-722e-4ed4-b5e6-7d23b412f76e",
    "_uuid": "278b1c63-81b5-4675-b607-9b8ccf9d4dd4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-24T14:33:16.294554Z",
     "iopub.status.busy": "2025-08-24T14:33:16.294027Z",
     "iopub.status.idle": "2025-08-24T14:33:47.289725Z",
     "shell.execute_reply": "2025-08-24T14:33:47.288492Z",
     "shell.execute_reply.started": "2025-08-24T14:33:16.294516Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-24 14:33:21.197666: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756046001.593065      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756046001.700375      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting visualkeras\n",
      "  Downloading visualkeras-0.1.4-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from visualkeras) (11.2.1)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.11/dist-packages (from visualkeras) (1.26.4)\n",
      "Collecting aggdraw>=1.3.11 (from visualkeras)\n",
      "  Downloading aggdraw-1.3.19-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (655 bytes)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.1->visualkeras) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.1->visualkeras) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.1->visualkeras) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.1->visualkeras) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.1->visualkeras) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.1->visualkeras) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.1->visualkeras) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.1->visualkeras) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.1->visualkeras) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.18.1->visualkeras) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.18.1->visualkeras) (2024.2.0)\n",
      "Downloading visualkeras-0.1.4-py3-none-any.whl (17 kB)\n",
      "Downloading aggdraw-1.3.19-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (997 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.4/997.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: aggdraw, visualkeras\n",
      "Successfully installed aggdraw-1.3.19 visualkeras-0.1.4\n",
      "Collecting vit_keras\n",
      "  Downloading vit_keras-0.2.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vit_keras) (1.15.3)\n",
      "Collecting validators (from vit_keras)\n",
      "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->vit_keras) (1.26.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->vit_keras) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->vit_keras) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->vit_keras) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->vit_keras) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->vit_keras) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->vit_keras) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->vit_keras) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->vit_keras) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.5,>=1.23.5->scipy->vit_keras) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.5,>=1.23.5->scipy->vit_keras) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.5,>=1.23.5->scipy->vit_keras) (2024.2.0)\n",
      "Downloading vit_keras-0.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: validators, vit_keras\n",
      "Successfully installed validators-0.35.0 vit_keras-0.2.0\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "# Image Processing\n",
    "from skimage.filters import sobel\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Model, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Common Layers\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Flatten, Input,\n",
    "    Conv2D, SeparableConv2D, Conv2DTranspose,\n",
    "    Concatenate, Add, Activation,\n",
    "    GlobalAveragePooling2D, GlobalMaxPooling2D,\n",
    "    MaxPooling2D, AveragePooling2D, BatchNormalization\n",
    ")\n",
    "\n",
    "# Pretrained Models\n",
    "from tensorflow.keras.applications import (\n",
    "    VGG16, VGG19, ResNet50, ResNet101,\n",
    "    EfficientNetB0, EfficientNetB2, EfficientNetB3,\n",
    "    EfficientNetB4, EfficientNetB5, EfficientNetB6,\n",
    "    InceptionResNetV2, MobileNetV2\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Visualization\n",
    "import visualkeras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "93427d7e-4b50-428a-8c66-e5125ec08413",
    "_uuid": "7eea9f39-6d54-490d-a5ae-c2db888397b3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-24T14:33:47.292787Z",
     "iopub.status.busy": "2025-08-24T14:33:47.291748Z",
     "iopub.status.idle": "2025-08-24T14:33:47.299031Z",
     "shell.execute_reply": "2025-08-24T14:33:47.298385Z",
     "shell.execute_reply.started": "2025-08-24T14:33:47.292759Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "####  Transition Layer  ######\n",
    "def transition_block(inputs):\n",
    "    x = tf.keras.layers.SeparableConv2D(filters=64, kernel_size=1)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.SeparableConv2D(filters=128, kernel_size=3, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.SeparableConv2D(filters=256, kernel_size=1)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    #x = tf.keras.layers.UpSampling2D((2,2))(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2,2))(x)\n",
    "    \n",
    "\n",
    "   \n",
    "    return x\n",
    "\n",
    "def additionalL(inputs):\n",
    "    x = tf.keras.layers.SeparableConv2D(filters=256, kernel_size=1)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "bde9d5b1-6f59-406e-aacc-05915d34efac",
    "_uuid": "43e60988-466b-476e-84dd-3b728dcd80c2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-24T14:33:47.299775Z",
     "iopub.status.busy": "2025-08-24T14:33:47.299544Z",
     "iopub.status.idle": "2025-08-24T14:33:47.317667Z",
     "shell.execute_reply": "2025-08-24T14:33:47.317002Z",
     "shell.execute_reply.started": "2025-08-24T14:33:47.299758Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def transition_layer(inputs):\n",
    "    x = Conv2D(512, (1, 1), padding='valid', activation='relu')(inputs)\n",
    "    while x.shape[1] > 4:  # Adjust to your desired output size\n",
    "        x = Conv2D(512, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "f05271bb-b89a-4cb4-9dc0-2ca77c3fa555",
    "_uuid": "d0feec23-b5fe-4466-977b-d88ff2810a5a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-24T14:33:50.426369Z",
     "iopub.status.busy": "2025-08-24T14:33:50.426051Z",
     "iopub.status.idle": "2025-08-24T14:33:50.430556Z",
     "shell.execute_reply": "2025-08-24T14:33:50.430003Z",
     "shell.execute_reply.started": "2025-08-24T14:33:50.426320Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def VM(input_size = (128,128,3),input = input):\n",
    "    vision_model = vit.vit_b16(input_size[0])(input)\n",
    "    M= tf.keras.Model(inputs=input, outputs=vision_model)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "af996081-24db-429b-adc6-985f498d1385",
    "_uuid": "c7809c88-4cfa-4ad9-b3be-8c00e8adb646",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-24T14:33:50.506082Z",
     "iopub.status.busy": "2025-08-24T14:33:50.505903Z",
     "iopub.status.idle": "2025-08-24T14:33:50.523599Z",
     "shell.execute_reply": "2025-08-24T14:33:50.523065Z",
     "shell.execute_reply.started": "2025-08-24T14:33:50.506068Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16, ResNet50, VGG19,ResNet101\n",
    "from vit_keras import vit, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9fbde838-ac70-41ea-8f90-9209072eb999",
    "_uuid": "3ebd9d04-5932-4b78-be0e-8dcbc29d10a7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-24T14:33:50.524528Z",
     "iopub.status.busy": "2025-08-24T14:33:50.524257Z",
     "iopub.status.idle": "2025-08-24T14:33:50.542847Z",
     "shell.execute_reply": "2025-08-24T14:33:50.542160Z",
     "shell.execute_reply.started": "2025-08-24T14:33:50.524506Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def make_model(input_size=(128, 128, 3)):\n",
    "    input_tensor = Input(shape=input_size)\n",
    "\n",
    "    # Load VGG19 model without top layers and freeze its weights\n",
    "    base_model1 = VGG19(include_top=False, weights='imagenet', pooling='max',\n",
    "                        input_shape=input_size, input_tensor=input_tensor)\n",
    "    for layer in base_model1.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Load ResNet50 model without top layers and freeze its weights\n",
    "    base_model2 = ResNet50(include_top=False, weights='imagenet', pooling='max',\n",
    "                           input_shape=input_size, input_tensor=input_tensor)\n",
    "    for layer in base_model2.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Load Vision Transformer output\n",
    "    vision_output = VM(input_size, input_tensor)\n",
    "\n",
    "    # Extract intermediate layers from VGG19 for bi-fusion and feature fusion\n",
    "    last_layer11 = base_model1.get_layer('block3_conv2').output\n",
    "    last_layer12 = base_model1.get_layer('block4_conv3').output\n",
    "    last_layer13 = base_model1.get_layer('block5_conv1').output\n",
    "    last_layer14 = base_model1.get_layer('block5_conv3').output\n",
    "    last_layer15 = base_model1.get_layer('block5_pool').output\n",
    "\n",
    "    # Extract intermediate layers from ResNet50 for bi-fusion and feature fusion\n",
    "    last_layer21 = base_model2.get_layer('conv2_block1_out').output\n",
    "    last_layer22 = base_model2.get_layer('conv3_block4_out').output\n",
    "    last_layer23 = base_model2.get_layer('conv4_block4_out').output\n",
    "    last_layer24 = base_model2.get_layer('conv4_block6_out').output\n",
    "    last_layer25 = base_model2.get_layer('conv5_block3_out').output\n",
    "\n",
    "    # Apply transition block 2 to VGG19 feature maps to get uniform 4x4x256 shape\n",
    "    vgg1 = transition_layer(last_layer11)\n",
    "    vgg2 = transition_layer(last_layer12)\n",
    "    vgg3 = transition_layer(last_layer13)\n",
    "    vgg4 = transition_layer(last_layer14)\n",
    "\n",
    "    # Apply transition block 2 to ResNet50 feature maps to get uniform 4x4x256 shape\n",
    "    resnet1 = transition_layer(last_layer21)\n",
    "    resnet2 = transition_layer(last_layer22)\n",
    "    resnet3 = transition_layer(last_layer23)\n",
    "    resnet4 = transition_layer(last_layer24)\n",
    "\n",
    "    # Bi-fusion of corresponding VGG19 and ResNet50 features\n",
    "    merge1 = tf.keras.layers.Concatenate(axis=-1)([vgg1, resnet1])\n",
    "    merge2 = tf.keras.layers.Concatenate(axis=-1)([vgg2, resnet2])\n",
    "    merge3 = tf.keras.layers.Concatenate(axis=-1)([vgg3, resnet3])\n",
    "    merge4 = tf.keras.layers.Concatenate(axis=-1)([vgg4, resnet4])\n",
    "\n",
    "    # Feature fusion: combine merged features to form left and right feature streams\n",
    "    outputL = tf.keras.layers.Concatenate(axis=-1)([merge1, merge3])\n",
    "    outputR = tf.keras.layers.Concatenate(axis=-1)([merge2, merge4])\n",
    "\n",
    "    # Passing left fused features through Transition Block 1\n",
    "    outputLT = transition_block(outputL)\n",
    "    outputLA = additionalL(outputL)\n",
    "    outputL = tf.keras.layers.Concatenate(axis=-1)([outputLT, outputLA])\n",
    "\n",
    "    # Passing right fused features through Transition Block 1\n",
    "    outputRT = transition_block(outputR)\n",
    "    outputRA = additionalL(outputR)\n",
    "    outputR = tf.keras.layers.Concatenate(axis=-1)([outputRT, outputRA])\n",
    "\n",
    "    # Combine left and right streams\n",
    "    output2 = tf.keras.layers.Concatenate(axis=-1)([outputL, outputR])\n",
    "\n",
    "    # Apply Transition Block 1 to ResNet50 final feature map\n",
    "    resnetT = transition_block(last_layer25)\n",
    "    resnetA = additionalL(last_layer25)\n",
    "    resnetout = tf.keras.layers.Concatenate(axis=-1)([resnetT, resnetA])\n",
    "\n",
    "    # Merge VGG19 final pooling layer with processed ResNet50 output\n",
    "    output1 = tf.keras.layers.Concatenate(axis=-1)([last_layer15, resnetout])\n",
    "\n",
    "    # Merge output1 and output2 to form ensemble feature representation\n",
    "    output_ensemble = tf.keras.layers.Concatenate(axis=-1)([output1, output2])\n",
    "\n",
    "    # Flatten ensemble features before dense layers\n",
    "    flatten = Flatten()(output_ensemble)\n",
    "    dense1 = Dense(256, activation='relu')(flatten)\n",
    "\n",
    "    # Dense layers for Vision Transformer output\n",
    "    vision_dense = Dense(256, activation='relu')(vision_output)\n",
    "\n",
    "    # Merge CNN dense features with Vision Transformer features\n",
    "    combined_dense = Concatenate()([dense1, vision_dense])\n",
    "\n",
    "    # Fully connected layers with dropout for regularization\n",
    "    combined_dense = Dropout(0.2)(combined_dense)\n",
    "    combined_dense = Dense(128, activation='relu')(combined_dense)\n",
    "    combined_dense = Dropout(0.3)(combined_dense)\n",
    "    combined_dense = Dense(64, activation='relu')(combined_dense)\n",
    "\n",
    "    # Final classification layer with 5 classes\n",
    "    model_output = Dense(5, activation='softmax', dtype='float32')(combined_dense)\n",
    "\n",
    "    # Build and compile the model\n",
    "    M = Model(inputs=input_tensor, outputs=model_output)\n",
    "    M.compile(optimizer=Adamax(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1a84f3df-18f7-4fea-985f-7df4bec98568",
    "_uuid": "6293df88-e2fb-4f99-af7f-3ef1f2872c9c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-24T14:33:50.543883Z",
     "iopub.status.busy": "2025-08-24T14:33:50.543657Z",
     "iopub.status.idle": "2025-08-24T14:34:02.350303Z",
     "shell.execute_reply": "2025-08-24T14:34:02.349723Z",
     "shell.execute_reply.started": "2025-08-24T14:33:50.543862Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5015 files belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756046040.281587      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1756046040.282265      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# ###########  For batch size 128 ###########\n",
    "data = tf.keras.utils.image_dataset_from_directory(directory = '/kaggle/input/cervical-preprocessed/Processed Dataset',\n",
    "                                                   color_mode = 'rgb',\n",
    "                                                   batch_size = 128,\n",
    "                                                   image_size = (128,128),\n",
    "                                                   shuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "089987df-518a-4ae3-8f1f-7de32f4a44d3",
    "_uuid": "9e2cebe3-7008-4436-8e1b-a39e4bf9bcee",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-24T14:34:02.353032Z",
     "iopub.status.busy": "2025-08-24T14:34:02.352809Z",
     "iopub.status.idle": "2025-08-24T14:34:06.465357Z",
     "shell.execute_reply": "2025-08-24T14:34:06.464820Z",
     "shell.execute_reply.started": "2025-08-24T14:34:02.353016Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "# #model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "83736f2e-b02d-496e-8304-b660e92181d2",
    "_uuid": "e3ecd6d8-c612-4c03-adf4-fd7277a939e1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-24T14:34:06.466188Z",
     "iopub.status.busy": "2025-08-24T14:34:06.466007Z",
     "iopub.status.idle": "2025-08-24T14:34:35.527290Z",
     "shell.execute_reply": "2025-08-24T14:34:35.526669Z",
     "shell.execute_reply.started": "2025-08-24T14:34:06.466174Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "leng = len(data)\n",
    "n_folds = 5  # number of folds here\n",
    "\n",
    "train_size = int(0.7 * leng)\n",
    "test_size = int(0.3 * leng)\n",
    "\n",
    "train = data.take(train_size)\n",
    "\n",
    "remaining2 = data.skip(train_size)\n",
    "test = remaining2.take(test_size)\n",
    "\n",
    "\n",
    "# calculate the size of each fold\n",
    "fold_size = train.cardinality().numpy() // n_folds\n",
    "\n",
    "# initialize lists to store the folds and remainders\n",
    "folds = []\n",
    "remainders = [train]\n",
    "\n",
    "# loop over the number of folds and create each fold\n",
    "for i in range(n_folds):\n",
    "    # take the first `fold_size` samples from the current remainder to create a fold\n",
    "    fold = remainders[-1].take(fold_size)\n",
    "    \n",
    "    # append the fold to the list of folds\n",
    "    folds.append(fold)\n",
    "    \n",
    "    # skip the samples in the fold to create the next remainder\n",
    "    remainder = remainders[-1].skip(fold_size)\n",
    "    \n",
    "    # append the remainder to the list of remainders\n",
    "    remainders.append(remainder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################## Test Itera ####################\n",
    "\n",
    "test_iter = test.as_numpy_iterator()\n",
    "\n",
    "test_set = {\"images\":np.empty((0,128,128,3)), \"labels\":np.empty(0)}\n",
    "while True:\n",
    "    try:\n",
    "        batch = test_iter.next()\n",
    "        test_set['images'] = np.concatenate((test_set['images'], batch[0]))\n",
    "        test_set['labels'] = np.concatenate((test_set['labels'], batch[1]))\n",
    "    except:\n",
    "        break\n",
    "\n",
    "y_true = test_set['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e0c14e40-d6a6-48d6-95c4-49cb35b9f196",
    "_uuid": "1244c71c-485e-4712-8d67-81b2571aa1b1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-24T14:34:35.528301Z",
     "iopub.status.busy": "2025-08-24T14:34:35.528069Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  0\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756046113.749643     119 service.cc:148] XLA service 0x799328002a20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1756046113.752627     119 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1756046113.752650     119 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1756046117.888650     119 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-08-24 14:35:46.598131: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{k11=2} for conv (f32[128,512,33,33]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,512,16,16]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-08-24 14:35:46.917788: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.319853806s\n",
      "Trying algorithm eng4{k11=2} for conv (f32[128,512,33,33]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,512,16,16]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "E0000 00:00:1756046153.518601     119 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1756046153.684791     119 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "I0000 00:00:1756046161.441806     119 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.3856 - loss: 4.9640 - val_accuracy: 0.3415 - val_loss: 3.4393\n",
      "Epoch 2/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.6003 - loss: 1.1648 - val_accuracy: 0.5022 - val_loss: 1.5879\n",
      "Epoch 3/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.6991 - loss: 0.8370 - val_accuracy: 0.4833 - val_loss: 1.6512\n",
      "Epoch 4/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.7358 - loss: 0.7212 - val_accuracy: 0.5893 - val_loss: 1.1032\n",
      "Epoch 5/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.7824 - loss: 0.6001 - val_accuracy: 0.6540 - val_loss: 0.9338\n",
      "Epoch 6/40\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - accuracy: 0.8225 - loss: 0.4850 - val_accuracy: 0.7522 - val_loss: 0.6767\n",
      "Epoch 7/40\n",
      "\u001b[1m23/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8376 - loss: 0.4631"
     ]
    }
   ],
   "source": [
    "\n",
    "# early_stop = EarlyStopping(\n",
    "#     monitor=\"val_accuracy\", \n",
    "#     patience=10,\n",
    "#     verbose=1,\n",
    "#     mode=\"max\",\n",
    "#     restore_best_weights=True, \n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,5):\n",
    "\n",
    "    model = make_model()\n",
    "    f1_scores = []\n",
    "    sn_scores = []\n",
    "    ppv_scores = []\n",
    "    test_accuracies = []\n",
    "    test_loss = []\n",
    "    kappa_scores = []\n",
    "    specificity_scores = []\n",
    "    print(\"Fold: \",i)\n",
    "    # create a list of folds to use as the training set\n",
    "    train_folds = [f for j, f in enumerate(folds) if j != i]\n",
    "\n",
    "    # concatenate the training folds into a single dataset\n",
    "    train_data = tf.data.experimental.sample_from_datasets(train_folds)\n",
    "\n",
    "    # train the model using the training data and the current fold as the validation data\n",
    "    history = model.fit(train_data, epochs = 40, validation_data=folds[i])\n",
    "    model.save(f\"/kaggle/working/model_fold_{i+1}.h5\")\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_results = model.evaluate(test)\n",
    "\n",
    "    # Extract the evaluation metrics\n",
    "    test_loss_value = test_results[0]\n",
    "    test_accuracy = test_results[1]\n",
    "\n",
    "\n",
    "\n",
    "    # Perform necessary calculations for the evaluation metrics (e.g., F1-score, Sensitivity, PPV, Kappa)\n",
    "    y_pred = model.predict(test_set['images'])\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    f1_score1 = f1_score(y_true, y_pred_classes, average='macro')\n",
    "    sn = recall_score(y_true, y_pred_classes, average='macro')\n",
    "    ppv = precision_score(y_true, y_pred_classes, average='macro')\n",
    "    kappa = cohen_kappa_score(y_true, y_pred_classes)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "    # Extract TN (True Negatives) and FP (False Positives) from the confusion matrix\n",
    "    TN = conf_matrix[0, 0]\n",
    "    FP = conf_matrix[0, 1]\n",
    "\n",
    "    # Calculate specificity\n",
    "    specificity = TN / (TN + FP)\n",
    "\n",
    "    # Store the evaluation metrics for the current fold\n",
    "    f1_scores.append(f1_score1)\n",
    "    sn_scores.append(sn)\n",
    "    ppv_scores.append(ppv)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    test_loss.append(test_loss_value)\n",
    "    kappa_scores.append(kappa)\n",
    "    specificity_scores.append(specificity)\n",
    "\n",
    "\n",
    "\n",
    "    # Get the accuracy, loss, recall, and sensitivity for each epoch\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "\n",
    "    # Write the accuracy, loss, recall, and sensitivity to a CSV file\n",
    "    output_file_path = '/kaggle/working/accuracy_loss_recall_sensitivity.csv'\n",
    "\n",
    "    with open(output_file_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Epoch', 'Train-Accuracy', 'Validation Accuracy', 'Train-Loss', 'Validation Loss', 'F1-Score', 'Sensitivity','Precition','Test-Acc','Test-Loss','Kappa','Specificity'])\n",
    "            for j in range(len(acc)):\n",
    "                writer.writerow([j+1, acc[j], val_acc[j], loss[j], val_loss[j], f1_scores, sn_scores,ppv_scores,test_accuracies,test_loss,kappa_scores,specificity_scores])\n",
    "\n",
    "    destination_file_path = '/kaggle/working/Bifusion_(-vit)_model_Fold ' + str(i+1) + '.csv'\n",
    "    shutil.copy(output_file_path, destination_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ae704672-555b-4732-a1de-dedefebc4550",
    "_uuid": "eea28041-a572-4f0e-8020-eba016f18ddc",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Calculate FLOPs\n",
    "# flops = get_flops(model, batch_size=1)\n",
    "# print(f\"FLOPs: {flops / 10**9:.03} G\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7442056,
     "sourceId": 11844715,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
